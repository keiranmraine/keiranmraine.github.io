{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Husband, father, software-developer / bioinformatician. Current position Principal Software developer, Cancer Ageing and Somatic Mutation (CASM), Wellcome Sanger Institute . Much of my development time is spent improving the usability of the teams code, specifically with the intent of making it possible for collaborators to reproduce findings independently using the same software stack. You can find more detail here . Global Projects I am a member of the following initiatives: ICGC ARGO Data Management Working group Occasional consultation, not regular attendee PPCG Technical working group Occasional consultation, not regular attendee I was heavily involved in the ICGC PanCancer Analysis of Whole Genomes as a member of: * Technical working group * QC working group GitHub ORCID You can view my publications via the ORCID system: https://orcid.org/0000-0002-5634-1539","title":"Home"},{"location":"#home","text":"Husband, father, software-developer / bioinformatician.","title":"Home"},{"location":"#current-position","text":"Principal Software developer, Cancer Ageing and Somatic Mutation (CASM), Wellcome Sanger Institute . Much of my development time is spent improving the usability of the teams code, specifically with the intent of making it possible for collaborators to reproduce findings independently using the same software stack. You can find more detail here .","title":"Current position"},{"location":"#global-projects","text":"I am a member of the following initiatives: ICGC ARGO Data Management Working group Occasional consultation, not regular attendee PPCG Technical working group Occasional consultation, not regular attendee I was heavily involved in the ICGC PanCancer Analysis of Whole Genomes as a member of: * Technical working group * QC working group","title":"Global Projects"},{"location":"#github","text":"","title":"GitHub"},{"location":"#orcid","text":"You can view my publications via the ORCID system: https://orcid.org/0000-0002-5634-1539","title":"ORCID"},{"location":"Education_and_Skills/","text":"Education & Skills Education M.Sc. Bioinformatics University of Manchester 2001-2002 Project Finding the immunogenic needle in the immunological haystack: a comparative study of context dependent text mining. Edward Jenner Institute for Vaccine Research Supervisor Dr Darren Flower B.Sc. (Hons) Biomedical Sciences, 2:1 University of Durham 1998-2001 Project The Chromosome 19 Limb-Girdle Muscular Dystrophy Gene (LGMD2I). Candidate Gene Analysis. University of Durham, Department of Biosciences Supervisor Dr Rumaisa Bashir Skills Soft skills Active Bystander - September 2020 Wellcome Sanger Institute Management in Action - 2018-2019 Talking Ape Unconscious Bias in Recruitment and Selection - October 2017 Challenge Consultancy AGILE: Agile Testing Strategies - July 2013 Learning Tree - course 1815 Scripting and programming languages python (3) General scripting, packages Database access Web-services Cython, pyCuda Recent skill development perl 18 years experience Object Oriented design CGI, DBI bash proficient Cloud, virtualisation and related tools AWS General use of virtual instances and volumes. Polly for training video voice-overs. OpenStack Tools for host management and deployment, applicable to other environments but used mainly here: Packer - image building Terraform - infrastructure deployment Containerisation tools Docker Use of build stages for smaller deployments Experience of docker-swarm Singularity Mainly usage and ensuring docker containers are compatible. More portable to develop via Dockerfile and convert. Specialised registries - workflow + container Dockstore Web-development nginx HTML, CSS - intermediate JavaScript - proficient React - slightly stale Databases Oracle - main experience including query optimisation. SQLite, PostgreSQL, MySQL Version control git/GitHub/GitLab GitFlow/HubFLow methodology preferred SVN CVS Genome browsers JBrowse Configuration and usage Plugin development GBrowse Configuration and usage IGV Configuration and usage Other development skills This section details languages I have some experience but would not consider myself to be proficient. Workflow languages Common Workflow Language Nexflow - training and debugging of flows generated by others only NodeJS Microservice development C/C++ Compilation, Makefile correction Online courses, Debugging R Debugging, investigating and cleaning up code for pipelines/external use. Library installation Message Queues RabbitMQ - https://github.com/cancerit/WwDocker (JAVA) JAVA Used intermittently over 15 years, stale","title":"Education & Skills"},{"location":"Education_and_Skills/#education-skills","text":"","title":"Education &amp; Skills"},{"location":"Education_and_Skills/#education","text":"","title":"Education"},{"location":"Education_and_Skills/#msc-bioinformatics","text":"University of Manchester 2001-2002 Project Finding the immunogenic needle in the immunological haystack: a comparative study of context dependent text mining. Edward Jenner Institute for Vaccine Research Supervisor Dr Darren Flower","title":"M.Sc. Bioinformatics"},{"location":"Education_and_Skills/#bsc-hons-biomedical-sciences-21","text":"University of Durham 1998-2001 Project The Chromosome 19 Limb-Girdle Muscular Dystrophy Gene (LGMD2I). Candidate Gene Analysis. University of Durham, Department of Biosciences Supervisor Dr Rumaisa Bashir","title":"B.Sc. (Hons) Biomedical Sciences, 2:1"},{"location":"Education_and_Skills/#skills","text":"","title":"Skills"},{"location":"Education_and_Skills/#soft-skills","text":"Active Bystander - September 2020 Wellcome Sanger Institute Management in Action - 2018-2019 Talking Ape Unconscious Bias in Recruitment and Selection - October 2017 Challenge Consultancy AGILE: Agile Testing Strategies - July 2013 Learning Tree - course 1815","title":"Soft skills"},{"location":"Education_and_Skills/#scripting-and-programming-languages","text":"python (3) General scripting, packages Database access Web-services Cython, pyCuda Recent skill development perl 18 years experience Object Oriented design CGI, DBI bash proficient","title":"Scripting and programming languages"},{"location":"Education_and_Skills/#cloud-virtualisation-and-related-tools","text":"AWS General use of virtual instances and volumes. Polly for training video voice-overs. OpenStack Tools for host management and deployment, applicable to other environments but used mainly here: Packer - image building Terraform - infrastructure deployment Containerisation tools Docker Use of build stages for smaller deployments Experience of docker-swarm Singularity Mainly usage and ensuring docker containers are compatible. More portable to develop via Dockerfile and convert. Specialised registries - workflow + container Dockstore","title":"Cloud, virtualisation and related tools"},{"location":"Education_and_Skills/#web-development","text":"nginx HTML, CSS - intermediate JavaScript - proficient React - slightly stale","title":"Web-development"},{"location":"Education_and_Skills/#databases","text":"Oracle - main experience including query optimisation. SQLite, PostgreSQL, MySQL","title":"Databases"},{"location":"Education_and_Skills/#version-control","text":"git/GitHub/GitLab GitFlow/HubFLow methodology preferred SVN CVS","title":"Version control"},{"location":"Education_and_Skills/#genome-browsers","text":"JBrowse Configuration and usage Plugin development GBrowse Configuration and usage IGV Configuration and usage","title":"Genome browsers"},{"location":"Education_and_Skills/#other-development-skills","text":"This section details languages I have some experience but would not consider myself to be proficient. Workflow languages Common Workflow Language Nexflow - training and debugging of flows generated by others only NodeJS Microservice development C/C++ Compilation, Makefile correction Online courses, Debugging R Debugging, investigating and cleaning up code for pipelines/external use. Library installation Message Queues RabbitMQ - https://github.com/cancerit/WwDocker (JAVA) JAVA Used intermittently over 15 years, stale","title":"Other development skills"},{"location":"profile/","text":"Work history 2002-2007 I originally joined the Cancer Genome Project (CGP) at the Sanger Institute (now CASM) in 2002 on completion of my M.Sc in Bioinformatics. At that time I was responsible for developing an integrated Laboratory Information Management System (LIMS) to support PCR heteroduplex analysis. This involved database design, Perl-CGI web-development and integration of TECAN lab robots. This system continues to be used largely unchanged for sample tracking in the CASM laboratory. During this time I also contributed to very early versions of the COSMIC database . During 2004 CGP moved heavily into capillary sequencing (also known as Sanger sequencing ). Once the LIMS was adapted I moved on to developing a high throughput pipeline to run the autoCSA analysis software. The control software was written using JAVA, and a public desktop application, a.k.a. StandaloneCSA , was created for the external use and release early 2007. This was a large project involving many developers working together on various aspects including database design, the analysis pipeline itself and a web-application used for visual inspection of the called variants by scientific staff. 2007-2009 In 2007 I left the CGP and joined Roche Pharmaceuticals as a Clinical Programmer. Here I gained experience of good clinical practice while building data capture and cleaning tools using Oracle Clinical . 2009-Current After 2 years at Roche I returned to the CGP in 2009. Although this may seem an unusual career choice the advent of next generation sequencing had significantly changed the challenges and work being undertaken. One of the primary differences in the data was the sheer volume being generated. Analysis pipelines The initial project was to create a pipeline to run the mapping of Illumina paired-end sequencing , supporting multiple species and builds. Over 6 months I extended an existing database, developed a new web-application and file tracking system to control the scheduling and flow of data into and out of a Platform LSF compute farm. After the initial 6 months the success of the project resulted in it being extended to support the downstream analysis tools with more of the team moving in to aid in both support and development. During this phase of the project the web-interfaces were extended significantly to allow the scientific staff to manage their data and analysis. The system proved to be a work-horse for the group for 6 years. The core jobs submission mechanism has been reworked by the group in the last few years, but the core database and much of the web-application has remained largely unchanged. Genome browsers As part of the analysis pipeline work I brought GBrowse into the the group as a centrally managed genome browser. GBrowse relies on server side compute and a traditional database backend to provide the images. In 2012 JBrowse matured to a state where BAM data could be directly handled in the browser. Due to this, and no further development on GBrowse, we have been actively working with the GMOD community to ensure features of GBrowse that our scientific staff consider important are replicated. We formally retired our GBrowse instance a few years ago. During 2016 I developed a plugin for JBrowse, proportionalMultiBw (prototyped in my own time) to aid in the visualization of allele fraction in regions of very high sequencing depth. I've additionally produced a general purpose tool for automating generation of screen shots, see cgpJBrowseToolkit . The new JBrowse 2 embraces this screenshot feature making this a core component of this new version of the tool (not based on my code). Global projects In 2014 the CGP became involved in the ICGC PanCancer Analysis of Whole Genomes project. As part of this a significant portion of the IT team spent 6 months preparing all of the core algorithms we use in house for public use. In addition to this work I was a member of the technical working group advising on tools, mapping strategy and creating tools to aid the submission of the raw sequencing data from the sequencing sites around the world. Working closely with the IT group at OICR I implemented the 'Sanger' pipeline into the framework to be used in multiple data centers around the world. This pipeline ran successfully in 13 locations on a variety of base infrastructures including AWS, Azure, OpenStack and traditional HPC. Following on from this project I continue to advise in the ICGC-ARGO data management group and the [PPCG][ ppcg-url technical working group. Containers for reproducible science In 2016 I developed cgpbox as an initial prototype providing our wholegenome analysis platform in a convenient to use docker image. This was well received and we continue to build on this with the dockstore framework (see above). Variations on \"cgpbox\" have been used to drive the PPCG project analysis and are in use by ICGC-ARGO at GDC Following on from this I have lead the initiative to convert all of our analysis pipelines to use containers. This has allowed us to offer our users the ability to fix algorithm versions for the life of their analysis projects. Full stack development experience During 2017 I prototyped a full-stack system for receipt of external sequencing data via web-interface and S3, backed by web-services hosted in our OpenStack flexible compute farm. Some of this can be viewed here . Following on from this a small team was formed to take this project further, developing the service architecture to validate the input data. Sadly the decision was taken to pause this project, however a great deal of new technology was investigated and this has proven to be valuable for subsequent projects. Readers note Above I have detailed projects that I have been heavily involved in. Although I may have worked exclusively on some of these it should be noted that I value the advice and expertise of those around me. The 'cancerit' team is an excellent group of people from varied backgrounds who draw on each others strengths. The team is also supported by the core informatics and infrastructure groups at the Sanger Institute.","title":"Work history"},{"location":"profile/#work-history","text":"","title":"Work history"},{"location":"profile/#2002-2007","text":"I originally joined the Cancer Genome Project (CGP) at the Sanger Institute (now CASM) in 2002 on completion of my M.Sc in Bioinformatics. At that time I was responsible for developing an integrated Laboratory Information Management System (LIMS) to support PCR heteroduplex analysis. This involved database design, Perl-CGI web-development and integration of TECAN lab robots. This system continues to be used largely unchanged for sample tracking in the CASM laboratory. During this time I also contributed to very early versions of the COSMIC database . During 2004 CGP moved heavily into capillary sequencing (also known as Sanger sequencing ). Once the LIMS was adapted I moved on to developing a high throughput pipeline to run the autoCSA analysis software. The control software was written using JAVA, and a public desktop application, a.k.a. StandaloneCSA , was created for the external use and release early 2007. This was a large project involving many developers working together on various aspects including database design, the analysis pipeline itself and a web-application used for visual inspection of the called variants by scientific staff.","title":"2002-2007"},{"location":"profile/#2007-2009","text":"In 2007 I left the CGP and joined Roche Pharmaceuticals as a Clinical Programmer. Here I gained experience of good clinical practice while building data capture and cleaning tools using Oracle Clinical .","title":"2007-2009"},{"location":"profile/#2009-current","text":"After 2 years at Roche I returned to the CGP in 2009. Although this may seem an unusual career choice the advent of next generation sequencing had significantly changed the challenges and work being undertaken. One of the primary differences in the data was the sheer volume being generated.","title":"2009-Current"},{"location":"profile/#analysis-pipelines","text":"The initial project was to create a pipeline to run the mapping of Illumina paired-end sequencing , supporting multiple species and builds. Over 6 months I extended an existing database, developed a new web-application and file tracking system to control the scheduling and flow of data into and out of a Platform LSF compute farm. After the initial 6 months the success of the project resulted in it being extended to support the downstream analysis tools with more of the team moving in to aid in both support and development. During this phase of the project the web-interfaces were extended significantly to allow the scientific staff to manage their data and analysis. The system proved to be a work-horse for the group for 6 years. The core jobs submission mechanism has been reworked by the group in the last few years, but the core database and much of the web-application has remained largely unchanged.","title":"Analysis pipelines"},{"location":"profile/#genome-browsers","text":"As part of the analysis pipeline work I brought GBrowse into the the group as a centrally managed genome browser. GBrowse relies on server side compute and a traditional database backend to provide the images. In 2012 JBrowse matured to a state where BAM data could be directly handled in the browser. Due to this, and no further development on GBrowse, we have been actively working with the GMOD community to ensure features of GBrowse that our scientific staff consider important are replicated. We formally retired our GBrowse instance a few years ago. During 2016 I developed a plugin for JBrowse, proportionalMultiBw (prototyped in my own time) to aid in the visualization of allele fraction in regions of very high sequencing depth. I've additionally produced a general purpose tool for automating generation of screen shots, see cgpJBrowseToolkit . The new JBrowse 2 embraces this screenshot feature making this a core component of this new version of the tool (not based on my code).","title":"Genome browsers"},{"location":"profile/#global-projects","text":"In 2014 the CGP became involved in the ICGC PanCancer Analysis of Whole Genomes project. As part of this a significant portion of the IT team spent 6 months preparing all of the core algorithms we use in house for public use. In addition to this work I was a member of the technical working group advising on tools, mapping strategy and creating tools to aid the submission of the raw sequencing data from the sequencing sites around the world. Working closely with the IT group at OICR I implemented the 'Sanger' pipeline into the framework to be used in multiple data centers around the world. This pipeline ran successfully in 13 locations on a variety of base infrastructures including AWS, Azure, OpenStack and traditional HPC. Following on from this project I continue to advise in the ICGC-ARGO data management group and the [PPCG][ ppcg-url technical working group.","title":"Global projects"},{"location":"profile/#containers-for-reproducible-science","text":"In 2016 I developed cgpbox as an initial prototype providing our wholegenome analysis platform in a convenient to use docker image. This was well received and we continue to build on this with the dockstore framework (see above). Variations on \"cgpbox\" have been used to drive the PPCG project analysis and are in use by ICGC-ARGO at GDC Following on from this I have lead the initiative to convert all of our analysis pipelines to use containers. This has allowed us to offer our users the ability to fix algorithm versions for the life of their analysis projects.","title":"Containers for reproducible science"},{"location":"profile/#full-stack-development-experience","text":"During 2017 I prototyped a full-stack system for receipt of external sequencing data via web-interface and S3, backed by web-services hosted in our OpenStack flexible compute farm. Some of this can be viewed here . Following on from this a small team was formed to take this project further, developing the service architecture to validate the input data. Sadly the decision was taken to pause this project, however a great deal of new technology was investigated and this has proven to be valuable for subsequent projects.","title":"Full stack development experience"},{"location":"profile/#readers-note","text":"Above I have detailed projects that I have been heavily involved in. Although I may have worked exclusively on some of these it should be noted that I value the advice and expertise of those around me. The 'cancerit' team is an excellent group of people from varied backgrounds who draw on each others strengths. The team is also supported by the core informatics and infrastructure groups at the Sanger Institute.","title":"Readers note"},{"location":"blogs/2021/05/updating-my-site/","text":"Refreshing my site I've decided to refresh this for a couple of reasons: It looks a little tired. Originally created doing it \"my way\", mainly as a \"live CV\". I feel like I have something to contribute via blog posts. Interested in including some user interaction/feedback. Choosing a site generator My original site already worked from markdown files and I want to continue like this. I pretty much write all my documentation in markdown. Here are the items I looked at: Jekyll MkDocs Material for MkDocs Jekyll Jekyll is a well established static site generator, with direct integration into github pages. This seemed like the obvious place to start as I'm going to host it on github-pages. I quickly found that if you've worked with other site generators Jekyll can feel overly complex. I suspect this is due to flexibility, but for what I needed it was too much. I also wasn't a big fan of the available themes. MkDocs Full disclosure, I've used MkDocs before for my work at Sanger and I already know how to use it. Quite simply if you want to provide a site that is easy to navigate all you need to do in MkDocs is structure things in a document tree as you want to see it in the site menu: docs/ \u251c\u2500\u2500 blogs \u2502 \u2514\u2500\u2500 2021 \u2502 \u2514\u2500\u2500 05 \u2502 \u2514\u2500\u2500 updating-my-site.md \u2514\u2500\u2500 index.md The above requires no configuration at all, but obviously you still want to do some. Before I go further, I want my site to have a clean look and feel. MkDocs has a limited number of themes, Read the Docs isn't bad but there is an extension project which I recently used and have found it good. As I'm leaning towards MkDocs over Jekyll, lets take that next step before I get bogged down on layout and content... MkDocs Material This was the selected tool (at time of writing). As the title suggests, this is MkDocs focused on Material Design components. The first thing you notice when you apply the material theme is that you automatically get a left and right sidebar. The left sidebar gives you the site navigation, very similar to the document tree: This will automatically change to a hamburger menu button if the view is narrow. On the right the table of content for the current document is shown. Interaction As I'm thinking of writing blog posts semi-regularly it makes sense to give people the ability to interact via comments. This is hosted in the GitHub eco-system and I don't really want to be pushing people to another service for comments so I did a little digging and found utterances . This basically uses the repositories issue tracking system to allow comments, see it in action below. Comments","title":"Refreshing my site"},{"location":"blogs/2021/05/updating-my-site/#refreshing-my-site","text":"I've decided to refresh this for a couple of reasons: It looks a little tired. Originally created doing it \"my way\", mainly as a \"live CV\". I feel like I have something to contribute via blog posts. Interested in including some user interaction/feedback.","title":"Refreshing my site"},{"location":"blogs/2021/05/updating-my-site/#choosing-a-site-generator","text":"My original site already worked from markdown files and I want to continue like this. I pretty much write all my documentation in markdown. Here are the items I looked at: Jekyll MkDocs Material for MkDocs","title":"Choosing a site generator"},{"location":"blogs/2021/05/updating-my-site/#jekyll","text":"Jekyll is a well established static site generator, with direct integration into github pages. This seemed like the obvious place to start as I'm going to host it on github-pages. I quickly found that if you've worked with other site generators Jekyll can feel overly complex. I suspect this is due to flexibility, but for what I needed it was too much. I also wasn't a big fan of the available themes.","title":"Jekyll"},{"location":"blogs/2021/05/updating-my-site/#mkdocs","text":"Full disclosure, I've used MkDocs before for my work at Sanger and I already know how to use it. Quite simply if you want to provide a site that is easy to navigate all you need to do in MkDocs is structure things in a document tree as you want to see it in the site menu: docs/ \u251c\u2500\u2500 blogs \u2502 \u2514\u2500\u2500 2021 \u2502 \u2514\u2500\u2500 05 \u2502 \u2514\u2500\u2500 updating-my-site.md \u2514\u2500\u2500 index.md The above requires no configuration at all, but obviously you still want to do some. Before I go further, I want my site to have a clean look and feel. MkDocs has a limited number of themes, Read the Docs isn't bad but there is an extension project which I recently used and have found it good. As I'm leaning towards MkDocs over Jekyll, lets take that next step before I get bogged down on layout and content...","title":"MkDocs"},{"location":"blogs/2021/05/updating-my-site/#mkdocs-material","text":"This was the selected tool (at time of writing). As the title suggests, this is MkDocs focused on Material Design components. The first thing you notice when you apply the material theme is that you automatically get a left and right sidebar. The left sidebar gives you the site navigation, very similar to the document tree: This will automatically change to a hamburger menu button if the view is narrow. On the right the table of content for the current document is shown.","title":"MkDocs Material"},{"location":"blogs/2021/05/updating-my-site/#interaction","text":"As I'm thinking of writing blog posts semi-regularly it makes sense to give people the ability to interact via comments. This is hosted in the GitHub eco-system and I don't really want to be pushing people to another service for comments so I did a little digging and found utterances . This basically uses the repositories issue tracking system to allow comments, see it in action below.","title":"Interaction"},{"location":"blogs/2021/05/updating-my-site/#comments","text":"","title":"Comments"}]}